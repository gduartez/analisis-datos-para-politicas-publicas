{"title":"Estadística Descriptiva","markdown":{"yaml":{"bibliography":"references.bib"},"headingText":"Estadística Descriptiva","headingAttr":{"id":"sec-descriptivo","classes":[],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n\n\n```{r setup, include=FALSE, purl = FALSE}\nlibrary(skimr)\nlibrary(knitr)\nlibrary(tidyverse)\nlibrary(vtable)\nlibrary(r2resize)\nlibrary(chilemapas)\nlibrary(dplyr)\nlibrary(gapminder)\nlibrary(kableExtra)\nlibrary(readr)\nlibrary(patchwork)\nlibrary(scales)\nlibrary(stringr)\nlibrary(corrplot)\n\n# # Definir una lista de los paquetes a utilizar\n# paquetes <- c('palmerpenguins','ggthemes','plotly',\n#               'fBasics','grid','gridExtra','datasets', 'nycflights13', 'chilemapas',\"tidyverse\",\n#               'moderndive','kableExtra','nycflights13', 'patchwork','gapminder')\n# \n# # Loop para instalar y cargar los paquetes\n# for (paquete in paquetes) {\n#   if (!requireNamespace(paquete, quietly = TRUE)) {\n#     install.packages(paquete)\n#   }\n#   library(paquete, character.only = TRUE, quietly = TRUE)\n# }\n```\n\nEste capítulo tiene como objetivo general enseñar las nociones básicas de la estadística a través del uso del software `R`.\n\nComo objetivos específicos se busca:\n\n-   Conocer la utilidad de la estadística y el origen de la ciencia de datos.\n-   Aplicar mediante `R` estadísticas descriptivas para diversos conjuntos de datos.\n-   Repasar (o aprender) las nociones básicas de la probabilidad.\n\n## Estadística  \n\n- En un sentido amplio, la estadística se define como una disciplina que, basada en determinadas metodologías y conceptos, consiste en *producir, analizar, procesar, interpretar y presentar un conjunto de datos*.\n\n- Dos ideas fundamentales en el campo de la estadística son la **incertidumbre** y la **variación**. En este sentido, la estadística y la probabilidad se basan en métodos tanto para describir y modelar esta variabilidad, así como para tomar decisiones en presencia de ella.\n\n-   Las principales dos ramas de la estadística son la **estadística descriptiva** y la **estadística inferencial**:\n\n    -   **Estadística Descriptiva:** Consiste en métodos para **organizar y resumir datos**.\n    -   **Estadística Inferencial:** Consiste en obtener conclusiones a partir de una **muestra** de datos.\n\n### Orígines del *Data Science*\n\n-   Originalmente, la estadística clásica se centraba casi\n    exclusivamente en la **inferencia**, un conjunto de procedimientos para sacar conclusiones sobre poblaciones grandes basadas en muestras pequeñas.\n\n-   No obstante, en el año 1962, John Turkey ya comentaba sobre una reformulación de la estadística en su paper *The Future of Data Analysis* [@tukey1962] abogando por una nueva disciplina llamada *data analysis*, en donde la inferencia era solo un componente de ella:\n    \n    > [...My central interest is in data analysis, which I take to include, among other things: procedures for analyzing data, techniques for interpreting the results of such procedures, ways  of planning the gathering of data to make its analysis easier, more precise or more accurate, and all the machinery and results of (mathematical) statistics which apply to analyzing data...\\]\n\n-   En 1977 con su libro *Exploratory Data Analysis* [@tukey1977] propone utilizar gráficos sencillos (tales como boxplots y scatterplots) en conjunto con estadísticas de resumen (tales como la media, la mediana, cuantiles, etc.) para tener una primera impresión general del conjunto de datos que se analiza.\n\n### ¿Data Science o Estadística?\n\n-   Segun [AWS](https://aws.amazon.com/es/what-is/data-science/#:~:text=La%20estad%C3%ADstica%20es%20un%20campo,los%20datos%20de%20maneras%20diversas.), la estadística es un campo con bases matemáticas que busca recopilar e interpretar datos cuantitativos. En cambio, la ciencia de datos es un campo **multidisciplinario** que utiliza métodos, procesos y sistemas científicos para extraer conocimientos a partir de los datos de maneras diversas. Los científicos de datos utilizan métodos de muchas disciplinas, incluida la estadística. Sin embargo, los campos difieren en sus procesos y los problemas que estudian.\n\n-   Yanir Seroussi [@seroussi2014], [en su\n    post](https://yanirseroussi.com/2014/10/23/what-is-data-science/), define como Data Scientist a aquella persona que es mejor en estadística que cualquier ingeniero de software y mejor en ingeniería de software que cualquier estadístico. Argumenta que, para él, la novedad principal de la ciencia de datos proviene de la aplicación de softwares para modelar **cualquier** tipo de datos de una manera que se generalice en todos los dominios.\n\n![](images/data-skill-continuum.png)\n\n\n-   El campo de la estadística guarda relación con la recopilación,\n    análisis y uso de datos para tomar decisiones y resolver problemas.\n-   Las 2 ramas principales de la estadística son la **descriptiva** y\n    la **inferencial**.\n-   El análisis de datos implica más procesos que solamente el uso de la\n    estadística.\n-   La estadística es sola una parte de lo que podemos entender por\n    ciencia de datos en su concepción más general.\n\n## Tipos de Datos\n\n-   **Numéricos:** Datos que son expresados en una escala numérica.\n    Pueden clasificarse en:\n    -   [Continuos:]{.underline} Datos que pueden tomar cualquier valor\n        en un intervalo.\n    -   [Discretos:]{.underline} Datos que sólo pueden tomar valores\n        enteros, tales como los recuentos.\n-   **Categóricos:** Datos que solo pueden tomar valores específicos\n    sobre un set de posibles categorías. Pueden clasificarse en:\n    -   [Nominales:]{.underline} Categorías que no se pueden ordenar ni\n        clasificar.\n        -   [Binarios:]{.underline} Un caso especial de datos\n            categóricos con solo dos categorías de valores, por ejemplo:\n            0/1, verdadero/falso.\n    -   [Ordinales:]{.underline} Datos categóricos que tienen un orden\n        explícito.\n\nLos tipos de datos se pueden resumir según el siguiente esquema:\n\n![Fuente:\n[@çetinkaya-rundel2021]](images/tipos_de_datos.png){fig-align=\"center\"\nwidth=\"90%\"}\n\n### Datos Rectangulares\n\n-   **Dataframe:** Los datos rectangulares (aquellos que comúnmente asociamos a una hoja de cálculo) son la estructura de datos básica  para los modelos estadísticos.\n-   **Feature:** Corresponde a las columnas o variables de la tabla de datos (sinónimos: *attribute*, *input*, *predictor*, *variable*).\n-   **Outcome:** Muchos proyectos de ciencia de datos tienen por objetivo predecir un resultado de interés o *outcome*. Las *features* a veces se utilizan para predecir el resultado de un experimento o estudio. (sinónimos: *dependent variable*, *response*, *target*, *output*).\n-   **Records:** Una observación o *record* corresponde comúnmente a una fila dentro de una tabla. (sinónimos: *case*, *instance*,*observation*).\n\n::: {.fragment .fade-in}\n![](images/tidydata.png){width=\"50%\" fig-align=\"center\"}\n:::\n\nVeamos un  ejemplo de datos ordenados en formato rectangular y *tidy* [@bryan2023]\n\n```{r, echo=FALSE, purl=FALSE}\ngapminder_2007 <- gapminder %>%\n  filter(year == 2007 & continent == 'Americas') %>%\n  select(-year) %>%\n  rename(\n    País = country,\n    Continente = continent,\n    `Esperanza de Vida` = lifeExp,\n    `Población` = pop,\n    `PIB per Cápita` = gdpPercap\n  )\n```\n\n```{r gapminder-2007, echo=FALSE, purl=FALSE}\ngapminder_2007 |> \n  slice(1:5) |> \n  kable(\n    digits = 2,\n    format.args = list(big.mark = \".\", decimal.mark = \",\"),\n    caption = \"Datos Gapminder 2007: 5 Países de América\" # ,\n  ) %>%\n  kable_styling(\n    font_size = ifelse(is_latex_output(), 20, 30),\n    latex_options = c(\"hold_position\")\n  )\n```\n\n::: fragment\n::: callout-tip\n### Ideas Principales\n\n-   Los tipos de datos incluyen **numéricos** (continuos, discretos) y\n    **categóricos** (nominales, binarios, ordinales).\n-   La tipificación de datos dentro de un software es importante para\n    indicarle cómo debe procesar los datos.\n-   La estructura de datos básica en la ciencia de datos es una **matriz\n    rectangular** (*dataframe*) en la que las filas son registros\n    (*records*) y las columnas son variables (*features*).\n:::\n:::\n\n## Medidas de tendencia central\n\nUn paso básico para explorar datos cuantitativos es obtener un *valor\ntípico* para cada variable: una estimación de dónde se encuentran la\nmayoría de los datos (es decir, su tendencia central). Las más típicas\nson:\n\n-   Media\n-   Media Ponderada\n-   Media Recortada\n-   Mediana\n-   Percentiles\n\n### Media (*Mean*)\n\nLa media es la suma de todos los valores dividido por la cantidad de valores considerados (n = total de observaciones):\n$$Media = \\bar{x} = {\\frac {1}{n}}\\sum _{i=1}^{n}x_{i}={\\frac {x_{1}+x_{2}+\\cdots +x_{n}}{n}}$$\n\n#### Aplicación \n\nSupongamos que tenemos los números del 1 al 5: $$C_1 =\\{1,2,3,4,5\\}$$\n\n\n¿Cuál sería su media?\n\nPara resolver, bastaría con aplicar la fórmula:\n$\\bar{C_1} ={\\frac {1+2+3+4+5}{5}} = 3$ \n\nEn `R`, esto se realiza con la función `mean()`\n\n```{r media, echo=TRUE}\nmean(c(1,2,3,4,5))\n```\n\n#### Media y Valores Faltantes\n\nEs importante señalar que cuando se intenta calcular la media y existen valores faltantes, el resultado en `R` será siempre del tipo `NA`:\n\n```{r media_na1, echo=TRUE}\nmean(c(1,2,NA,4,5))\n```\n\nPara calcular la media de los valores válidos o existentes en estas situaciones, se debe utilizar el argumento `na.rm = T`:\n\n```{r media_na2}\n#| echo: TRUE\n#| eval: TRUE\n#| code-line-numbers: \"3\"\n\nmean(c(1,2,NA,4,5),\n     na.rm = T\n     )\n```\n\n### Media Ponderada (Weighted Mean)\n\nSe calcula multiplicando cada valor de datos $x_i$ por un peso $w_i$\nseleccionado y dividiendo su suma por la suma de los pesos. La fórmula\npara una media ponderada es:\n$${\\displaystyle {\\bar {x}}={\\frac {\\sum _{i=1}^{n}x_{i}w_{i}}{\\sum _{i=1}^{n}w_{i}}}={\\frac {x_{1}w_{1}+x_{2}w_{2}+x_{3}w_{3}+...+x_{n}w_{n}}{w_{1}+w_{2}+w_{3}+...+w_{n}}}}$$\n\nLa media ponderada puede ser útil cuando:\n\n-   Algunos valores son intrínsecamente más variables que otros.\n-   Los datos recopilados no representan por igual a los diferentes\n    grupos que nos interesa medir.\n\nEn `R`, se puede calcular la media ponderada con la función\n`weighted.mean()`:\n\n```{r media_p, echo=TRUE}\nweighted.mean(c(1,2,3,4,5), c(4,4,2,2,1)/13)\n```\n\n![](images/light-bulb.png){width=\"5%\"} **¿Qué estoy haciendo en el\nsegundo argumento de la función?** [@freeico]\n\n### Media Recortada (Trimmed Mean)\n\nSe calcula eliminando un número fijo de valores ordenados en cada extremo y luego tomando un promedio de los valores restantes.\n\nRepresentando los valores ordenados por $x_1$, $x_2$, ...,$x_n$ donde $x_1$ es el valor más pequeño y $x_n$ el más grande, la fórmula para calcular la media recortada con los $p$ valores más pequeños y grandes omitidos es:\n\n$$Media\\ Recortada = {\\frac {\\sum _{i=p+1}^{n-p}x_{i}}{n-2p}}$$\n\n#### Aplicación  \n\n-   Por ejemplo, si queremos sacar 1 observación tanto en el extremo superior como el inferior del conjunto $C_1$, el resultado sería:\n    $\\bar{C_1}^{T} ={\\frac {2+3+4}{3}} = 3$\n\n-   Si generamos un nuevo conjunto $C_2 =\\{1,2,2,2,5\\}$ y recortamos el valor más alto y más bajo, el resultado sería: $\\bar{C_2}^{T} ={\\frac {2+2+2}{3}} = 2$ el cual es distinto al promedio simple del conjunto $C_2$:\n    $\\bar{C_2} ={\\frac {1+2+2+2+5}{5}} = 2.4$\n\nEn `R`, se puede especificar dentro de la función `mean()` el argumento `trim =`\n\n```{r media_t, echo=TRUE}\nmean(c(1,2,3,4,5), trim = 0.2)\nmean(c(1,2,2,2,5), trim = 0.2) \nmean(c(1,2,2,2,5))\n```\n\n![](images/light-bulb.png){width=\"5%\"} **¿Por qué ocupo**\n$trim = 0.2$?\n\n### Mediana \n\n-   La mediana es el número central en una lista ordenada de datos.\n-   Si hay un número par de valores de datos, el valor central en realidad no se encuentra en el conjunto de datos, sino que se obtiene a partir del promedio de los dos valores que dividen los datos ordenados en la mitad superior e inferior.\n-   La formula matemática de la mediana es la siguiente:\n\n$$\nMediana =\n\\begin{cases}\n x_\\frac{n}{2} + x_{\\frac{n}{2}+1} \\text{, si n es par} \\\\\n x_\\frac{n+1}{2}\\text{, si n es impar}\n \\end{cases}       \n$$\nEn comparación con la media, que utiliza todas las observaciones, la mediana depende sólo de los valores en el centro de los datos ordenados.\nSi bien esto puede parecer una desventaja, dado que la media es mucho\nmás sensible a los datos extremos, hay muchos casos en los que la\nmediana es una mejor métrica para describir la tendencia central de los\ndatos.\n\nEn `R`, la función que permite realizar esto es `median()`\n\n```{r median, echo=TRUE}\nmedian(c(1,2,3,4,5))\n```\n\n\n```{r median2, echo=TRUE}\nmedian(c(1,2,2,2,5))\n```\n\n```{r median3, echo=TRUE}\nmedian(c(1,2,3,4))\n```\n\n\n#### Ejemplo: Ingresos Laborales Chile (2022)\n\n![Fuente: Encuesta Suplementaria de Ingresos 2022,\nINE](images/ingreso_medio_chile.png){width=\"100%\"}\n\n#### Ejemplo: Ingresos Laborales Chile (2022)\n\n![Fuente: Encuesta Suplementaria de Ingresos 2022,\nINE](images/ingreso_mediano_chile.png){width=\"100%\"}\n\n::: callout-tip\n## Ideas Principales\n\n-   La métrica básica para tendencias centrales es la media, pero puede ser sensible a valores atípicos (*outliers*).\n-   Otras métricas como la mediana o la media recortada son menos sensibles a valores atípicos y, por lo tanto, son más robustas frente a valores extremos.\n:::\n\n## Medidas de Variabilidad\n\n### Desviación Media Absoluta  \n\n-   Las estimaciones de variación más utilizadas se basan en las diferencias o desviaciones entre una estimación de localización y los datos observados.\n-   Para un conjunto de datos $C4 = \\{1, 4, 4\\}$, la media es 3 y la  mediana es 4. Las desviaciones de la media son las diferencias: $1 – 3 = –2$, $4 – 3 = 1$, $4 – 3 = 1$.\n-   Estas desviaciones nos dicen **cuán dispersas** están los datos están alrededor del valor central.\n-   Una forma de medir la variabilidad es estimar un valor típico para estas desviaciones. Promediar las desviaciones en sí mismas no nos diría mucho: Las desviaciones negativas compensan las positivas. De hecho ¡la suma de las desviaciones de la media es precisamente cero! $\\sum_{i=1}^n (x-\\bar{x}) = 0$.\n-   Así, la desviación media absoluta (*mean absolute deviation*) se  define como: $$\\frac{\\sum_{i=1}^n |(x_i-\\bar{x})|}{n}$$\n\n### Desviación Estándar y Varianza  \n\n-   Las estimaciones de variabilidad más conocidas son la varianza y la desviación estándar, que se basan en desviaciones al cuadrado.\n-   La varianza es un promedio de las desviaciones al cuadrado y la desviación estándar es la raíz cuadrada de la varianza:\n\n\n$$\\operatorname{Varianza} = s^2 = \\frac{\\sum_{i=1}^n {(x_i-\\bar{x})}^2}{n-1}$$\n\n\n$$\\operatorname{Desviación\\ Estándar} = s = \\sqrt{\\operatorname{Varianza}}$$\n\n### Desviación Absoluta Mediana (*MAD*)  \n\n-   La desviación estándar es mucho más fácil de interpretar que la\n    varianza ya que está en la misma escala que los datos originales.\n-   Ni la varianza, ni la desviación estándar ni la desviación media\n    absoluta son robustas ante valores atípicos y extremos. La varianza\n    y la desviación estándar son especialmente sensibles a los valores\n    atípicos ya que se basan en desviaciones al cuadrado.\n-   Una estimación más robusta de la variabilidad es la desviación absoluta mediana de la mediana o MAD:$$MAD = Mediana(|x_1-m|,|x_2-m|,\\cdots,|x_n-m| )$$ donde $m$ es la mediana\n- En `R` esta se puede calcular a través de la función `mad()`\n\n#### Aplicación: Desviación Estándar y Varianza  \n\nPara obtener las medidas de variabilidad revisadas usando `R`, se pueden utilizar las siguientes funciones:\n\n- **Desviación Estándar:** `sd()`\n- **Varianza:** `var()`.\n- **Desviación Media Absoluta:** `mad()`\n\n\n\n```{r sd, echo=TRUE}\nsd(c(1, 4, 4))\nvar(c(1, 4, 4))\nmad(c(1, 4, 4))\n```\n\n\n-   Es importante recordar que cuando existen valores `NA`, se debe\n    especificar el argumento `na.rm = T`:\n\n\n```{r sd2, echo=TRUE}\nsd(c(1, 4, 4, NA), na.rm = T)\nvar(c(1, 4, 4, NA), na.rm = T)\nmad(c(1, 4, 4, NA), na.rm = T)\n```\n\n### Rango  \n\n-   El rango es la diferencia entre el valor más grande y el más pequeño\n    en un conjunto de datos.\n-   La fórmula matemática es sencilla: $$R =x_{max} - x_{min}$$\n\n\nEn R, los valores máximos y mínimos se pueden extraer mediante el\ncomando `range()`. Si se desea calcular el valor numérico del rango, se\ndebe utilizar las funciones `min()` y `max()`\n\n```{r range, echo=TRUE}\nrange(c(1, 4, 4))\nmax(c(1, 4, 4)) - min(c(1, 4, 4))\n```\n\n### Percentiles  \n\n-   El percentil es una medida estadística la cual divide una serie de\n    datos ordenados de menor a mayor en cien partes iguales. En términos concretos, un percentil corresponde al valor que permite ubicar a una cierta proporción de los datos ordenados.\n-   El percentil $P$ se define como un valor tal que $P$ por ciento de\n    los valores tome este valor o menos y $(100–P)$ por ciento tome este\n    valor o más.\n-   En este sentido, el percentil 50 es lo mismo que la mediana, pues es\n    la observación en donde se cumple que el 50% de los datos tienen un\n    valor igual o menor a él.\n-   El percentil es esencialmente lo mismo que un cuantil, solo que los\n    cuantiles son indexados por fracciones (por lo que el cuantil $.8$\n    es lo mismo que el percentil 80 ($P_{80}$).\n-   Es importante notar que **no existe una *única* forma** de calcular\n    los percentiles (ver detalle de la función). Sin embargo,\n    generalmente no es necesario preocuparse de qué tan preciso es el\n    cálculo del percentil y se puede usar el algoritmo que viene por\n    defecto con la función `quantile()`\n\n#### Aplicación  \n\n-   La función para calcular percentiles es `quantile()`. Sus argumentos\n    principales son:\n    -   `x`: El vector númerico sobre el cual se calculará el percentil\n    -   `probs =`: Vector numérico de las probabilidades P a calcular\n        (los percentiles) en un rango $[0,1]$\n\n\nVeamos un ejemplo usando R:\n\n```{r pctl1, echo=TRUE}\nc3 <- c(1,2,3,3,5,6,7,9)\nquantile(c3, probs = 0.5)\nmedian(c3)\n```\n\n\nProbemos ahora varios percentiles:\n\n```{r pctl2, echo=TRUE}\nquantile(c3, probs = c(0.1,0.25,0.5,0.75,0.9))\n```\n\n## Resumen de Estadísticas en R\n\n-   En `R`, existen diversos paquetes que permiten resumir las estadísticas más utilizadas de manera sencilla y ordenada. Estas funciones pueden facilitar el análisis exploratorio de los datos ejecutando solo unas pocas líneas de código.\n\nA continuación, revisaremos algunas de estas funciones y sus paquetes respectivos:\n\n### `summary()`\n\nLa función `summary()` entrega un resumen de las estadísticas más importantes, tales como el valor mínimo y máximo, la media y mediana, y el percentil 25 y 75.\n\nEsta función está dentro del paquete `base` de `R`, por lo que **no** es necesario cargar ninguna librería previamente para utilizar la función:\n\n\n```{r, echo=TRUE}\nsummary(c3)\n```\n\n### `skim()`\n\nUna función similar y un poco más completa es `skim()` del paquete `skimr`\n\n```{r skimr, echo=TRUE}\nyank(skim(c3), 'numeric')\n```\n\n### `gt_plt_summary`\n\nLa función `gt_plt_summary()` del paquete gtExtras en R permite agregar una visualización resumen dentro de una tabla generada con gt. Su propósito principal es proporcionar una representación visual de una variable dentro de la tabla, como una mini gráfica de barras, densidad o histograma.\n\n```{r gtextra}\n#| warning: false\n#| message: false\n\n\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(datasets)\n\ngt_plt_summary(iris)\n```\n\n\n## Outliers  \n\nLa mediana se conoce como una estimación **robusta** de tendencia\ncentral, ya que no está influenciada por valores atípicos (casos\nextremos) que podrían sesgar los resultados. Un valor atípico es\ncualquier valor que es muy distante de los otros valores en un conjunto\nde datos. La definición exacta de un valor atípico es algo subjetivo,\naunque se utilizan ciertas convenciones en varios resúmenes de datos. En\nparticular, al graficar *boxplots*, el criterio para definir los\noutliers es:\n\n$$\nOutlier =\n\\begin{cases}\n Q3 + (1.5*IQR) \\\\\n \\lor \\\\\n Q1 - (1.5*IQR)\n \\end{cases}       \n$$ donde $Q3$ es el percentil 25 o cuartil 1, $Q3$ es el percentil 75 o\ncuartil 3 y IQR es el rango intercuartílico que es igual a $Q3-Q1$:\n\n$$IQR = Q_3-Q_1$$\n\n## Visualización de Datos\n\n\n-   En el entorno del tidyverse, es posible graficar *boxplots* y otros\n    tipos de visualizaciones con código resumido a través del comando\n    `qplot()`. Los argumentos principales de la función son los\n    siguientes:\n    -   `x`: La variable a graficar en el eje de las abscisas (eje x).\n        Se escribe **sin comilas**\n    -   `y`: La variable a graficar en el eje de las ordenadas (eje y).\n        Se escribe **sin comilas**\n    -   `data`: El dataset desde donde se extraen los datos. Se escribe\n        **sin comilas**\n    -   `geom`: Objetos geométricos a graficar (puntos, lineas,\n        histogramas etc.). Se escribe **con comilas (' ' o \" \")**\n-   Por ejemplo, grafiquemos la evolución de los salarios medios de\n    ambos sexos entre 2018 y 2022:\n\n### Gráfico de Líneas  \n\n\n```{r ESI, echo=TRUE}\naños <- c(2018:2022)\ningreso_medio <- c(606.400,620.500,631.100,681.000,757.800)\ndf_ingresos <- tibble(años,ingreso_medio)\n\n```\n\n\n```{r ESI2, echo=TRUE}\nqplot(años,ingreso_medio,data = df_ingresos, geom = c('point', 'line'))\n```\n\n### Histograma\n\n-   Un histograma es una gráfica que nos permite observar la\n    distribución de una variable numérica usando barras. Cada barra\n    representa el número de veces (frecuencia) que se observaron datos\n    en un rango determinado.\n-   Para graficar un histograma R se puede ocupar la función `hist()` o\n    especificar en `qplot(geom = 'histogram')`\n\n\n```{r hist1, echo=TRUE}\ndata(gapminder)\nqplot(lifeExp,data = gapminder, geom = ('histogram'),color=I(\"black\"), fill=I(\"steelblue\"))\n```\n\n\n```{r hist2, echo=TRUE}\nhist(gapminder$lifeExp) #Similar pero con el comando base\n```\n\n### Boxplot  \n\n-   Una de las visualizaciones más utilizadas para describir la\n    variabilidad de una variable es el boxplot o *gráfico de caja y\n    bigotes*\n-   Este gráfico se compone de los siguientes elementos visuales:\n    -   **Caja:** Representa el percentil 75 y percentil 25 de la\n        distribución\n    -   **Linea Horizontal:** Representa la mediana de la distribución o\n        percentil 50\n    -   **Puntos:** Representan los valores atípicos (outliers) según la\n        fórmula vista anteriormente\n\n![](images/BoxPlot.PNG){width=\"50%\" fig-align=\"center\"}\n\n\n#### Aplicación: Boxplot  \n\n-   Para realizar un boxplot en `R` se puede utilizar la función base\n    `boxplot()` o especificar en `qplot(geom = 'boxplot')`\n\n\n```{r boxplot1, echo=TRUE}\ndata(gapminder)\nqplot('',lifeExp,data = gapminder, geom = ('boxplot'),color=I(\"black\"), fill=I(\"red\"))\n```\n\n\n```{r boxplot2, echo=TRUE}\nboxplot(gapminder$lifeExp) #Similar pero con el comando base\n```\n\n## Medidas de Asociación  \n\nLas medidas de asociación son herramientas estadísticas que permiten cuantificar la relación entre dos o más variables. Su propósito es describir el grado y la dirección en que una variable cambia en función de otra, ayudando a identificar patrones y tendencias en los datos.\n\nAlgunas de las medidas de asociación más utilizadas incluyen:\n\n- **Correlación de Pearson:** Mide la relación lineal entre dos variables **continuas**. Va de -1 (relación negativa perfecta) a 1 (relación positiva perfecta), donde 0 indica la ausencia de correlación.\n\n- **Coeficiente de Spearman:** Mide la relación entre dos variables ordinales o no necesariamente lineales.\n\n- **Razón de probabilidades (Odds Ratio, OR):** Común en estudios de caso-control, indica cuánto más probable es un evento en un grupo comparado con otro.\n\n**Razón de tasas/incidencia (Rate Ratio, RR):** Utilizada en estudios epidemiológicos para comparar la incidencia de un evento en distintos grupos.\n\n**Coeficiente de contingencia y chi-cuadrado:** Aplicados a variables categóricas para evaluar si existe asociación entre ellas.\n\n### Correlación  \n\nSe dice que las variables $X$ e $Y$ (cada una con datos cuantitativos) están correlacionadas **positivamente** si ocurre que cuando aumenta $X$, $Y$ también lo hace, o viceversa. Cuando $X$ aumenta e $Y$ disminuye, o viceversa, las variables están correlacionadas **negativamente**.\n\nEs importante notar que la correlación es una medida de **dependencia lineal** entre dos variables **cuantitativas**. Esto quiere decir, que puede ocurrir que 2 variables estén relacionadas de manera **no lineal** y, por lo tanto, exista una baja o nula correlación de pearson, lo que **no implica** que no haya asociación entre estas variables.\n\nPara calcular el coeficiente de correlación de Pearson, multiplicamos las desviaciones de la media de la variable 1 por las de la variable 2 y las dividimos por el producto de las desviaciones estándar respectivas:\n\n\n$$r=\\frac{\\sigma_{xy}}{{\\sigma _{x}\\sigma _{y}}} = {\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{(n-1) s_{x}s_{y}}}$$\n\n#### Interpretación de la Correlación  \n\n- El valor numérico de la correlación de pearson nos indica 2 cosas: la **fuerza** de la correlación (valor absoluto de la correlación: $|r|$) y en qué **dirección** va la correlación (signo de la correlación: $r <0$ o $r>0$).\n\n- El coeficiente de correlación es una métrica estandarizada, por lo que siempre oscila entre –1 (correlación negativa perfecta) a +1 (correlación positiva perfecta). Un coeficiente de correlación de 0 indica que **no hay correlación** o asociación lineal entre las variables.\n\n- Es importante notar que no existe una única interpretación de la fuerza de la correlación de pearson (en efecto, hay muchos rangos utilizados dependiendo de la disciplina, por ejemplo [ver aquí](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6107969/)). Sin embargo una regla de oro (quizás un poco estricta) es la siguiente [@devore2016]:\n  + $r = 0$: **No existe correlación**\n  + $0 < |r| \\leq 0.5$: **Correlación Débil**\n  + $0.5 < |r| < 0.8$: **Correlación Moderada**\n  + $0.8 \\leq  |r| < 1$: **Correlación Fuerte**\n  + $|r| = 1$: **Correlación Perfecta**\n\n#### Matriz de Correlaciones\n\n-   La matriz de correlaciones es una tabla donde las variables se\n    muestran tanto en filas como en columnas, y los valores de las\n    celdas son las correlaciones entre las variables.\n-   Esta matriz es necesaria para realizar los gráficos de correlación o\n    `corplots`. El comando en R para obtener esta matriz de\n    correlaciones es `cor()`\n\n\n```{r cor, echo=T}\ndata(\"USArrests\")\nhead(USArrests)\n```\n\n```{r co2, echo=TRUE}\ncor(USArrests)\n```\n\n### Visualización de Medidas de Asociación\n\nExisten dos formas clásicas de visualizar la relación lineal entre 2 variables cuantitativas:\n\n1. Gráficos de dispersión (*Scatterplot*)\n2. Correlograma\n\nPara realizar un scatterplot en `R`, utilicemos el dataset de `USArrests` que contiene datos delictuales de arrestos por cada 100.000 habitantes en los 50 estados de USA en 1973. \n\n```{r, echo=TRUE}\ndata(\"USArrests\")\ncor(USArrests$Murder,USArrests$Assault)\nqplot(Murder,Assault,data = USArrests)\n```\n\nSi quisiéramos ajustar una recta para visualizar si la relación es negativa o positiva y su magnitud (todo esto, según la pendiente de la recta), podemos agregar un `geom_smooth` y especificar que nos ajuste una recta a través del método de regresión lineal (`method = \"lm\"`)\n\n```{r, echo=TRUE}\ncor(USArrests$Murder,USArrests$Rape)\nqplot(Murder, Rape, data = USArrests, geom = c(\"point\", \"smooth\"), method = \"lm\")\n```\n\nSi buscamos visualizar las asociaciones entre distintas variables cuantiativas en un solo gráfico, podemos usar un correlograma mediante la función corrplot\n\n```{r, echo=TRUE}\nlibrary(corrplot)\n\nm <- cor(USArrests)\n\ncorrplot(m, \n         method ='number',\n         type=\"lower\", \n         tl.col=\"black\",pch.col = \"black\"\n         )\n```\n\n## Reflexiones finales [@bruce2020]\n\n::: callout-tip\n### Resumen\n\n-   El análisis de datos exploratorios (EDA), iniciado por John Tukey, sentó las bases para el campo de la ciencia de datos. La idea clave  de EDA es que el primer y más importante paso en cualquier proyecto basado en datos es observar los mismos. Al resumir y visualizar los datos, se puede obtener una valiosa intuición y comprensión del objetivo que se busca resolver.\n-   El conjunto diverso de herramientas y técnicas que está desarrollando la comunidad de código abierto, combinado con la versatilidad de `R` (y otros softwares de este estilo), ha creado una gran cantidad de formas de explorar y analizar datos.\n-   El análisis exploratorio debiese ser la piedra angular de cualquier proyecto de ciencia de datos.\n:::\n\n","srcMarkdownNoYaml":"\n\n# Estadística Descriptiva {#sec-descriptivo}\n\n\n```{r setup, include=FALSE, purl = FALSE}\nlibrary(skimr)\nlibrary(knitr)\nlibrary(tidyverse)\nlibrary(vtable)\nlibrary(r2resize)\nlibrary(chilemapas)\nlibrary(dplyr)\nlibrary(gapminder)\nlibrary(kableExtra)\nlibrary(readr)\nlibrary(patchwork)\nlibrary(scales)\nlibrary(stringr)\nlibrary(corrplot)\n\n# # Definir una lista de los paquetes a utilizar\n# paquetes <- c('palmerpenguins','ggthemes','plotly',\n#               'fBasics','grid','gridExtra','datasets', 'nycflights13', 'chilemapas',\"tidyverse\",\n#               'moderndive','kableExtra','nycflights13', 'patchwork','gapminder')\n# \n# # Loop para instalar y cargar los paquetes\n# for (paquete in paquetes) {\n#   if (!requireNamespace(paquete, quietly = TRUE)) {\n#     install.packages(paquete)\n#   }\n#   library(paquete, character.only = TRUE, quietly = TRUE)\n# }\n```\n\nEste capítulo tiene como objetivo general enseñar las nociones básicas de la estadística a través del uso del software `R`.\n\nComo objetivos específicos se busca:\n\n-   Conocer la utilidad de la estadística y el origen de la ciencia de datos.\n-   Aplicar mediante `R` estadísticas descriptivas para diversos conjuntos de datos.\n-   Repasar (o aprender) las nociones básicas de la probabilidad.\n\n## Estadística  \n\n- En un sentido amplio, la estadística se define como una disciplina que, basada en determinadas metodologías y conceptos, consiste en *producir, analizar, procesar, interpretar y presentar un conjunto de datos*.\n\n- Dos ideas fundamentales en el campo de la estadística son la **incertidumbre** y la **variación**. En este sentido, la estadística y la probabilidad se basan en métodos tanto para describir y modelar esta variabilidad, así como para tomar decisiones en presencia de ella.\n\n-   Las principales dos ramas de la estadística son la **estadística descriptiva** y la **estadística inferencial**:\n\n    -   **Estadística Descriptiva:** Consiste en métodos para **organizar y resumir datos**.\n    -   **Estadística Inferencial:** Consiste en obtener conclusiones a partir de una **muestra** de datos.\n\n### Orígines del *Data Science*\n\n-   Originalmente, la estadística clásica se centraba casi\n    exclusivamente en la **inferencia**, un conjunto de procedimientos para sacar conclusiones sobre poblaciones grandes basadas en muestras pequeñas.\n\n-   No obstante, en el año 1962, John Turkey ya comentaba sobre una reformulación de la estadística en su paper *The Future of Data Analysis* [@tukey1962] abogando por una nueva disciplina llamada *data analysis*, en donde la inferencia era solo un componente de ella:\n    \n    > [...My central interest is in data analysis, which I take to include, among other things: procedures for analyzing data, techniques for interpreting the results of such procedures, ways  of planning the gathering of data to make its analysis easier, more precise or more accurate, and all the machinery and results of (mathematical) statistics which apply to analyzing data...\\]\n\n-   En 1977 con su libro *Exploratory Data Analysis* [@tukey1977] propone utilizar gráficos sencillos (tales como boxplots y scatterplots) en conjunto con estadísticas de resumen (tales como la media, la mediana, cuantiles, etc.) para tener una primera impresión general del conjunto de datos que se analiza.\n\n### ¿Data Science o Estadística?\n\n-   Segun [AWS](https://aws.amazon.com/es/what-is/data-science/#:~:text=La%20estad%C3%ADstica%20es%20un%20campo,los%20datos%20de%20maneras%20diversas.), la estadística es un campo con bases matemáticas que busca recopilar e interpretar datos cuantitativos. En cambio, la ciencia de datos es un campo **multidisciplinario** que utiliza métodos, procesos y sistemas científicos para extraer conocimientos a partir de los datos de maneras diversas. Los científicos de datos utilizan métodos de muchas disciplinas, incluida la estadística. Sin embargo, los campos difieren en sus procesos y los problemas que estudian.\n\n-   Yanir Seroussi [@seroussi2014], [en su\n    post](https://yanirseroussi.com/2014/10/23/what-is-data-science/), define como Data Scientist a aquella persona que es mejor en estadística que cualquier ingeniero de software y mejor en ingeniería de software que cualquier estadístico. Argumenta que, para él, la novedad principal de la ciencia de datos proviene de la aplicación de softwares para modelar **cualquier** tipo de datos de una manera que se generalice en todos los dominios.\n\n![](images/data-skill-continuum.png)\n\n\n-   El campo de la estadística guarda relación con la recopilación,\n    análisis y uso de datos para tomar decisiones y resolver problemas.\n-   Las 2 ramas principales de la estadística son la **descriptiva** y\n    la **inferencial**.\n-   El análisis de datos implica más procesos que solamente el uso de la\n    estadística.\n-   La estadística es sola una parte de lo que podemos entender por\n    ciencia de datos en su concepción más general.\n\n## Tipos de Datos\n\n-   **Numéricos:** Datos que son expresados en una escala numérica.\n    Pueden clasificarse en:\n    -   [Continuos:]{.underline} Datos que pueden tomar cualquier valor\n        en un intervalo.\n    -   [Discretos:]{.underline} Datos que sólo pueden tomar valores\n        enteros, tales como los recuentos.\n-   **Categóricos:** Datos que solo pueden tomar valores específicos\n    sobre un set de posibles categorías. Pueden clasificarse en:\n    -   [Nominales:]{.underline} Categorías que no se pueden ordenar ni\n        clasificar.\n        -   [Binarios:]{.underline} Un caso especial de datos\n            categóricos con solo dos categorías de valores, por ejemplo:\n            0/1, verdadero/falso.\n    -   [Ordinales:]{.underline} Datos categóricos que tienen un orden\n        explícito.\n\nLos tipos de datos se pueden resumir según el siguiente esquema:\n\n![Fuente:\n[@çetinkaya-rundel2021]](images/tipos_de_datos.png){fig-align=\"center\"\nwidth=\"90%\"}\n\n### Datos Rectangulares\n\n-   **Dataframe:** Los datos rectangulares (aquellos que comúnmente asociamos a una hoja de cálculo) son la estructura de datos básica  para los modelos estadísticos.\n-   **Feature:** Corresponde a las columnas o variables de la tabla de datos (sinónimos: *attribute*, *input*, *predictor*, *variable*).\n-   **Outcome:** Muchos proyectos de ciencia de datos tienen por objetivo predecir un resultado de interés o *outcome*. Las *features* a veces se utilizan para predecir el resultado de un experimento o estudio. (sinónimos: *dependent variable*, *response*, *target*, *output*).\n-   **Records:** Una observación o *record* corresponde comúnmente a una fila dentro de una tabla. (sinónimos: *case*, *instance*,*observation*).\n\n::: {.fragment .fade-in}\n![](images/tidydata.png){width=\"50%\" fig-align=\"center\"}\n:::\n\nVeamos un  ejemplo de datos ordenados en formato rectangular y *tidy* [@bryan2023]\n\n```{r, echo=FALSE, purl=FALSE}\ngapminder_2007 <- gapminder %>%\n  filter(year == 2007 & continent == 'Americas') %>%\n  select(-year) %>%\n  rename(\n    País = country,\n    Continente = continent,\n    `Esperanza de Vida` = lifeExp,\n    `Población` = pop,\n    `PIB per Cápita` = gdpPercap\n  )\n```\n\n```{r gapminder-2007, echo=FALSE, purl=FALSE}\ngapminder_2007 |> \n  slice(1:5) |> \n  kable(\n    digits = 2,\n    format.args = list(big.mark = \".\", decimal.mark = \",\"),\n    caption = \"Datos Gapminder 2007: 5 Países de América\" # ,\n  ) %>%\n  kable_styling(\n    font_size = ifelse(is_latex_output(), 20, 30),\n    latex_options = c(\"hold_position\")\n  )\n```\n\n::: fragment\n::: callout-tip\n### Ideas Principales\n\n-   Los tipos de datos incluyen **numéricos** (continuos, discretos) y\n    **categóricos** (nominales, binarios, ordinales).\n-   La tipificación de datos dentro de un software es importante para\n    indicarle cómo debe procesar los datos.\n-   La estructura de datos básica en la ciencia de datos es una **matriz\n    rectangular** (*dataframe*) en la que las filas son registros\n    (*records*) y las columnas son variables (*features*).\n:::\n:::\n\n## Medidas de tendencia central\n\nUn paso básico para explorar datos cuantitativos es obtener un *valor\ntípico* para cada variable: una estimación de dónde se encuentran la\nmayoría de los datos (es decir, su tendencia central). Las más típicas\nson:\n\n-   Media\n-   Media Ponderada\n-   Media Recortada\n-   Mediana\n-   Percentiles\n\n### Media (*Mean*)\n\nLa media es la suma de todos los valores dividido por la cantidad de valores considerados (n = total de observaciones):\n$$Media = \\bar{x} = {\\frac {1}{n}}\\sum _{i=1}^{n}x_{i}={\\frac {x_{1}+x_{2}+\\cdots +x_{n}}{n}}$$\n\n#### Aplicación \n\nSupongamos que tenemos los números del 1 al 5: $$C_1 =\\{1,2,3,4,5\\}$$\n\n\n¿Cuál sería su media?\n\nPara resolver, bastaría con aplicar la fórmula:\n$\\bar{C_1} ={\\frac {1+2+3+4+5}{5}} = 3$ \n\nEn `R`, esto se realiza con la función `mean()`\n\n```{r media, echo=TRUE}\nmean(c(1,2,3,4,5))\n```\n\n#### Media y Valores Faltantes\n\nEs importante señalar que cuando se intenta calcular la media y existen valores faltantes, el resultado en `R` será siempre del tipo `NA`:\n\n```{r media_na1, echo=TRUE}\nmean(c(1,2,NA,4,5))\n```\n\nPara calcular la media de los valores válidos o existentes en estas situaciones, se debe utilizar el argumento `na.rm = T`:\n\n```{r media_na2}\n#| echo: TRUE\n#| eval: TRUE\n#| code-line-numbers: \"3\"\n\nmean(c(1,2,NA,4,5),\n     na.rm = T\n     )\n```\n\n### Media Ponderada (Weighted Mean)\n\nSe calcula multiplicando cada valor de datos $x_i$ por un peso $w_i$\nseleccionado y dividiendo su suma por la suma de los pesos. La fórmula\npara una media ponderada es:\n$${\\displaystyle {\\bar {x}}={\\frac {\\sum _{i=1}^{n}x_{i}w_{i}}{\\sum _{i=1}^{n}w_{i}}}={\\frac {x_{1}w_{1}+x_{2}w_{2}+x_{3}w_{3}+...+x_{n}w_{n}}{w_{1}+w_{2}+w_{3}+...+w_{n}}}}$$\n\nLa media ponderada puede ser útil cuando:\n\n-   Algunos valores son intrínsecamente más variables que otros.\n-   Los datos recopilados no representan por igual a los diferentes\n    grupos que nos interesa medir.\n\nEn `R`, se puede calcular la media ponderada con la función\n`weighted.mean()`:\n\n```{r media_p, echo=TRUE}\nweighted.mean(c(1,2,3,4,5), c(4,4,2,2,1)/13)\n```\n\n![](images/light-bulb.png){width=\"5%\"} **¿Qué estoy haciendo en el\nsegundo argumento de la función?** [@freeico]\n\n### Media Recortada (Trimmed Mean)\n\nSe calcula eliminando un número fijo de valores ordenados en cada extremo y luego tomando un promedio de los valores restantes.\n\nRepresentando los valores ordenados por $x_1$, $x_2$, ...,$x_n$ donde $x_1$ es el valor más pequeño y $x_n$ el más grande, la fórmula para calcular la media recortada con los $p$ valores más pequeños y grandes omitidos es:\n\n$$Media\\ Recortada = {\\frac {\\sum _{i=p+1}^{n-p}x_{i}}{n-2p}}$$\n\n#### Aplicación  \n\n-   Por ejemplo, si queremos sacar 1 observación tanto en el extremo superior como el inferior del conjunto $C_1$, el resultado sería:\n    $\\bar{C_1}^{T} ={\\frac {2+3+4}{3}} = 3$\n\n-   Si generamos un nuevo conjunto $C_2 =\\{1,2,2,2,5\\}$ y recortamos el valor más alto y más bajo, el resultado sería: $\\bar{C_2}^{T} ={\\frac {2+2+2}{3}} = 2$ el cual es distinto al promedio simple del conjunto $C_2$:\n    $\\bar{C_2} ={\\frac {1+2+2+2+5}{5}} = 2.4$\n\nEn `R`, se puede especificar dentro de la función `mean()` el argumento `trim =`\n\n```{r media_t, echo=TRUE}\nmean(c(1,2,3,4,5), trim = 0.2)\nmean(c(1,2,2,2,5), trim = 0.2) \nmean(c(1,2,2,2,5))\n```\n\n![](images/light-bulb.png){width=\"5%\"} **¿Por qué ocupo**\n$trim = 0.2$?\n\n### Mediana \n\n-   La mediana es el número central en una lista ordenada de datos.\n-   Si hay un número par de valores de datos, el valor central en realidad no se encuentra en el conjunto de datos, sino que se obtiene a partir del promedio de los dos valores que dividen los datos ordenados en la mitad superior e inferior.\n-   La formula matemática de la mediana es la siguiente:\n\n$$\nMediana =\n\\begin{cases}\n x_\\frac{n}{2} + x_{\\frac{n}{2}+1} \\text{, si n es par} \\\\\n x_\\frac{n+1}{2}\\text{, si n es impar}\n \\end{cases}       \n$$\nEn comparación con la media, que utiliza todas las observaciones, la mediana depende sólo de los valores en el centro de los datos ordenados.\nSi bien esto puede parecer una desventaja, dado que la media es mucho\nmás sensible a los datos extremos, hay muchos casos en los que la\nmediana es una mejor métrica para describir la tendencia central de los\ndatos.\n\nEn `R`, la función que permite realizar esto es `median()`\n\n```{r median, echo=TRUE}\nmedian(c(1,2,3,4,5))\n```\n\n\n```{r median2, echo=TRUE}\nmedian(c(1,2,2,2,5))\n```\n\n```{r median3, echo=TRUE}\nmedian(c(1,2,3,4))\n```\n\n\n#### Ejemplo: Ingresos Laborales Chile (2022)\n\n![Fuente: Encuesta Suplementaria de Ingresos 2022,\nINE](images/ingreso_medio_chile.png){width=\"100%\"}\n\n#### Ejemplo: Ingresos Laborales Chile (2022)\n\n![Fuente: Encuesta Suplementaria de Ingresos 2022,\nINE](images/ingreso_mediano_chile.png){width=\"100%\"}\n\n::: callout-tip\n## Ideas Principales\n\n-   La métrica básica para tendencias centrales es la media, pero puede ser sensible a valores atípicos (*outliers*).\n-   Otras métricas como la mediana o la media recortada son menos sensibles a valores atípicos y, por lo tanto, son más robustas frente a valores extremos.\n:::\n\n## Medidas de Variabilidad\n\n### Desviación Media Absoluta  \n\n-   Las estimaciones de variación más utilizadas se basan en las diferencias o desviaciones entre una estimación de localización y los datos observados.\n-   Para un conjunto de datos $C4 = \\{1, 4, 4\\}$, la media es 3 y la  mediana es 4. Las desviaciones de la media son las diferencias: $1 – 3 = –2$, $4 – 3 = 1$, $4 – 3 = 1$.\n-   Estas desviaciones nos dicen **cuán dispersas** están los datos están alrededor del valor central.\n-   Una forma de medir la variabilidad es estimar un valor típico para estas desviaciones. Promediar las desviaciones en sí mismas no nos diría mucho: Las desviaciones negativas compensan las positivas. De hecho ¡la suma de las desviaciones de la media es precisamente cero! $\\sum_{i=1}^n (x-\\bar{x}) = 0$.\n-   Así, la desviación media absoluta (*mean absolute deviation*) se  define como: $$\\frac{\\sum_{i=1}^n |(x_i-\\bar{x})|}{n}$$\n\n### Desviación Estándar y Varianza  \n\n-   Las estimaciones de variabilidad más conocidas son la varianza y la desviación estándar, que se basan en desviaciones al cuadrado.\n-   La varianza es un promedio de las desviaciones al cuadrado y la desviación estándar es la raíz cuadrada de la varianza:\n\n\n$$\\operatorname{Varianza} = s^2 = \\frac{\\sum_{i=1}^n {(x_i-\\bar{x})}^2}{n-1}$$\n\n\n$$\\operatorname{Desviación\\ Estándar} = s = \\sqrt{\\operatorname{Varianza}}$$\n\n### Desviación Absoluta Mediana (*MAD*)  \n\n-   La desviación estándar es mucho más fácil de interpretar que la\n    varianza ya que está en la misma escala que los datos originales.\n-   Ni la varianza, ni la desviación estándar ni la desviación media\n    absoluta son robustas ante valores atípicos y extremos. La varianza\n    y la desviación estándar son especialmente sensibles a los valores\n    atípicos ya que se basan en desviaciones al cuadrado.\n-   Una estimación más robusta de la variabilidad es la desviación absoluta mediana de la mediana o MAD:$$MAD = Mediana(|x_1-m|,|x_2-m|,\\cdots,|x_n-m| )$$ donde $m$ es la mediana\n- En `R` esta se puede calcular a través de la función `mad()`\n\n#### Aplicación: Desviación Estándar y Varianza  \n\nPara obtener las medidas de variabilidad revisadas usando `R`, se pueden utilizar las siguientes funciones:\n\n- **Desviación Estándar:** `sd()`\n- **Varianza:** `var()`.\n- **Desviación Media Absoluta:** `mad()`\n\n\n\n```{r sd, echo=TRUE}\nsd(c(1, 4, 4))\nvar(c(1, 4, 4))\nmad(c(1, 4, 4))\n```\n\n\n-   Es importante recordar que cuando existen valores `NA`, se debe\n    especificar el argumento `na.rm = T`:\n\n\n```{r sd2, echo=TRUE}\nsd(c(1, 4, 4, NA), na.rm = T)\nvar(c(1, 4, 4, NA), na.rm = T)\nmad(c(1, 4, 4, NA), na.rm = T)\n```\n\n### Rango  \n\n-   El rango es la diferencia entre el valor más grande y el más pequeño\n    en un conjunto de datos.\n-   La fórmula matemática es sencilla: $$R =x_{max} - x_{min}$$\n\n\nEn R, los valores máximos y mínimos se pueden extraer mediante el\ncomando `range()`. Si se desea calcular el valor numérico del rango, se\ndebe utilizar las funciones `min()` y `max()`\n\n```{r range, echo=TRUE}\nrange(c(1, 4, 4))\nmax(c(1, 4, 4)) - min(c(1, 4, 4))\n```\n\n### Percentiles  \n\n-   El percentil es una medida estadística la cual divide una serie de\n    datos ordenados de menor a mayor en cien partes iguales. En términos concretos, un percentil corresponde al valor que permite ubicar a una cierta proporción de los datos ordenados.\n-   El percentil $P$ se define como un valor tal que $P$ por ciento de\n    los valores tome este valor o menos y $(100–P)$ por ciento tome este\n    valor o más.\n-   En este sentido, el percentil 50 es lo mismo que la mediana, pues es\n    la observación en donde se cumple que el 50% de los datos tienen un\n    valor igual o menor a él.\n-   El percentil es esencialmente lo mismo que un cuantil, solo que los\n    cuantiles son indexados por fracciones (por lo que el cuantil $.8$\n    es lo mismo que el percentil 80 ($P_{80}$).\n-   Es importante notar que **no existe una *única* forma** de calcular\n    los percentiles (ver detalle de la función). Sin embargo,\n    generalmente no es necesario preocuparse de qué tan preciso es el\n    cálculo del percentil y se puede usar el algoritmo que viene por\n    defecto con la función `quantile()`\n\n#### Aplicación  \n\n-   La función para calcular percentiles es `quantile()`. Sus argumentos\n    principales son:\n    -   `x`: El vector númerico sobre el cual se calculará el percentil\n    -   `probs =`: Vector numérico de las probabilidades P a calcular\n        (los percentiles) en un rango $[0,1]$\n\n\nVeamos un ejemplo usando R:\n\n```{r pctl1, echo=TRUE}\nc3 <- c(1,2,3,3,5,6,7,9)\nquantile(c3, probs = 0.5)\nmedian(c3)\n```\n\n\nProbemos ahora varios percentiles:\n\n```{r pctl2, echo=TRUE}\nquantile(c3, probs = c(0.1,0.25,0.5,0.75,0.9))\n```\n\n## Resumen de Estadísticas en R\n\n-   En `R`, existen diversos paquetes que permiten resumir las estadísticas más utilizadas de manera sencilla y ordenada. Estas funciones pueden facilitar el análisis exploratorio de los datos ejecutando solo unas pocas líneas de código.\n\nA continuación, revisaremos algunas de estas funciones y sus paquetes respectivos:\n\n### `summary()`\n\nLa función `summary()` entrega un resumen de las estadísticas más importantes, tales como el valor mínimo y máximo, la media y mediana, y el percentil 25 y 75.\n\nEsta función está dentro del paquete `base` de `R`, por lo que **no** es necesario cargar ninguna librería previamente para utilizar la función:\n\n\n```{r, echo=TRUE}\nsummary(c3)\n```\n\n### `skim()`\n\nUna función similar y un poco más completa es `skim()` del paquete `skimr`\n\n```{r skimr, echo=TRUE}\nyank(skim(c3), 'numeric')\n```\n\n### `gt_plt_summary`\n\nLa función `gt_plt_summary()` del paquete gtExtras en R permite agregar una visualización resumen dentro de una tabla generada con gt. Su propósito principal es proporcionar una representación visual de una variable dentro de la tabla, como una mini gráfica de barras, densidad o histograma.\n\n```{r gtextra}\n#| warning: false\n#| message: false\n\n\nlibrary(gt)\nlibrary(gtExtras)\nlibrary(datasets)\n\ngt_plt_summary(iris)\n```\n\n\n## Outliers  \n\nLa mediana se conoce como una estimación **robusta** de tendencia\ncentral, ya que no está influenciada por valores atípicos (casos\nextremos) que podrían sesgar los resultados. Un valor atípico es\ncualquier valor que es muy distante de los otros valores en un conjunto\nde datos. La definición exacta de un valor atípico es algo subjetivo,\naunque se utilizan ciertas convenciones en varios resúmenes de datos. En\nparticular, al graficar *boxplots*, el criterio para definir los\noutliers es:\n\n$$\nOutlier =\n\\begin{cases}\n Q3 + (1.5*IQR) \\\\\n \\lor \\\\\n Q1 - (1.5*IQR)\n \\end{cases}       \n$$ donde $Q3$ es el percentil 25 o cuartil 1, $Q3$ es el percentil 75 o\ncuartil 3 y IQR es el rango intercuartílico que es igual a $Q3-Q1$:\n\n$$IQR = Q_3-Q_1$$\n\n## Visualización de Datos\n\n\n-   En el entorno del tidyverse, es posible graficar *boxplots* y otros\n    tipos de visualizaciones con código resumido a través del comando\n    `qplot()`. Los argumentos principales de la función son los\n    siguientes:\n    -   `x`: La variable a graficar en el eje de las abscisas (eje x).\n        Se escribe **sin comilas**\n    -   `y`: La variable a graficar en el eje de las ordenadas (eje y).\n        Se escribe **sin comilas**\n    -   `data`: El dataset desde donde se extraen los datos. Se escribe\n        **sin comilas**\n    -   `geom`: Objetos geométricos a graficar (puntos, lineas,\n        histogramas etc.). Se escribe **con comilas (' ' o \" \")**\n-   Por ejemplo, grafiquemos la evolución de los salarios medios de\n    ambos sexos entre 2018 y 2022:\n\n### Gráfico de Líneas  \n\n\n```{r ESI, echo=TRUE}\naños <- c(2018:2022)\ningreso_medio <- c(606.400,620.500,631.100,681.000,757.800)\ndf_ingresos <- tibble(años,ingreso_medio)\n\n```\n\n\n```{r ESI2, echo=TRUE}\nqplot(años,ingreso_medio,data = df_ingresos, geom = c('point', 'line'))\n```\n\n### Histograma\n\n-   Un histograma es una gráfica que nos permite observar la\n    distribución de una variable numérica usando barras. Cada barra\n    representa el número de veces (frecuencia) que se observaron datos\n    en un rango determinado.\n-   Para graficar un histograma R se puede ocupar la función `hist()` o\n    especificar en `qplot(geom = 'histogram')`\n\n\n```{r hist1, echo=TRUE}\ndata(gapminder)\nqplot(lifeExp,data = gapminder, geom = ('histogram'),color=I(\"black\"), fill=I(\"steelblue\"))\n```\n\n\n```{r hist2, echo=TRUE}\nhist(gapminder$lifeExp) #Similar pero con el comando base\n```\n\n### Boxplot  \n\n-   Una de las visualizaciones más utilizadas para describir la\n    variabilidad de una variable es el boxplot o *gráfico de caja y\n    bigotes*\n-   Este gráfico se compone de los siguientes elementos visuales:\n    -   **Caja:** Representa el percentil 75 y percentil 25 de la\n        distribución\n    -   **Linea Horizontal:** Representa la mediana de la distribución o\n        percentil 50\n    -   **Puntos:** Representan los valores atípicos (outliers) según la\n        fórmula vista anteriormente\n\n![](images/BoxPlot.PNG){width=\"50%\" fig-align=\"center\"}\n\n\n#### Aplicación: Boxplot  \n\n-   Para realizar un boxplot en `R` se puede utilizar la función base\n    `boxplot()` o especificar en `qplot(geom = 'boxplot')`\n\n\n```{r boxplot1, echo=TRUE}\ndata(gapminder)\nqplot('',lifeExp,data = gapminder, geom = ('boxplot'),color=I(\"black\"), fill=I(\"red\"))\n```\n\n\n```{r boxplot2, echo=TRUE}\nboxplot(gapminder$lifeExp) #Similar pero con el comando base\n```\n\n## Medidas de Asociación  \n\nLas medidas de asociación son herramientas estadísticas que permiten cuantificar la relación entre dos o más variables. Su propósito es describir el grado y la dirección en que una variable cambia en función de otra, ayudando a identificar patrones y tendencias en los datos.\n\nAlgunas de las medidas de asociación más utilizadas incluyen:\n\n- **Correlación de Pearson:** Mide la relación lineal entre dos variables **continuas**. Va de -1 (relación negativa perfecta) a 1 (relación positiva perfecta), donde 0 indica la ausencia de correlación.\n\n- **Coeficiente de Spearman:** Mide la relación entre dos variables ordinales o no necesariamente lineales.\n\n- **Razón de probabilidades (Odds Ratio, OR):** Común en estudios de caso-control, indica cuánto más probable es un evento en un grupo comparado con otro.\n\n**Razón de tasas/incidencia (Rate Ratio, RR):** Utilizada en estudios epidemiológicos para comparar la incidencia de un evento en distintos grupos.\n\n**Coeficiente de contingencia y chi-cuadrado:** Aplicados a variables categóricas para evaluar si existe asociación entre ellas.\n\n### Correlación  \n\nSe dice que las variables $X$ e $Y$ (cada una con datos cuantitativos) están correlacionadas **positivamente** si ocurre que cuando aumenta $X$, $Y$ también lo hace, o viceversa. Cuando $X$ aumenta e $Y$ disminuye, o viceversa, las variables están correlacionadas **negativamente**.\n\nEs importante notar que la correlación es una medida de **dependencia lineal** entre dos variables **cuantitativas**. Esto quiere decir, que puede ocurrir que 2 variables estén relacionadas de manera **no lineal** y, por lo tanto, exista una baja o nula correlación de pearson, lo que **no implica** que no haya asociación entre estas variables.\n\nPara calcular el coeficiente de correlación de Pearson, multiplicamos las desviaciones de la media de la variable 1 por las de la variable 2 y las dividimos por el producto de las desviaciones estándar respectivas:\n\n\n$$r=\\frac{\\sigma_{xy}}{{\\sigma _{x}\\sigma _{y}}} = {\\frac{\\sum_{i=1}^n(x_i-\\bar{x})(y_i-\\bar{y})}{(n-1) s_{x}s_{y}}}$$\n\n#### Interpretación de la Correlación  \n\n- El valor numérico de la correlación de pearson nos indica 2 cosas: la **fuerza** de la correlación (valor absoluto de la correlación: $|r|$) y en qué **dirección** va la correlación (signo de la correlación: $r <0$ o $r>0$).\n\n- El coeficiente de correlación es una métrica estandarizada, por lo que siempre oscila entre –1 (correlación negativa perfecta) a +1 (correlación positiva perfecta). Un coeficiente de correlación de 0 indica que **no hay correlación** o asociación lineal entre las variables.\n\n- Es importante notar que no existe una única interpretación de la fuerza de la correlación de pearson (en efecto, hay muchos rangos utilizados dependiendo de la disciplina, por ejemplo [ver aquí](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6107969/)). Sin embargo una regla de oro (quizás un poco estricta) es la siguiente [@devore2016]:\n  + $r = 0$: **No existe correlación**\n  + $0 < |r| \\leq 0.5$: **Correlación Débil**\n  + $0.5 < |r| < 0.8$: **Correlación Moderada**\n  + $0.8 \\leq  |r| < 1$: **Correlación Fuerte**\n  + $|r| = 1$: **Correlación Perfecta**\n\n#### Matriz de Correlaciones\n\n-   La matriz de correlaciones es una tabla donde las variables se\n    muestran tanto en filas como en columnas, y los valores de las\n    celdas son las correlaciones entre las variables.\n-   Esta matriz es necesaria para realizar los gráficos de correlación o\n    `corplots`. El comando en R para obtener esta matriz de\n    correlaciones es `cor()`\n\n\n```{r cor, echo=T}\ndata(\"USArrests\")\nhead(USArrests)\n```\n\n```{r co2, echo=TRUE}\ncor(USArrests)\n```\n\n### Visualización de Medidas de Asociación\n\nExisten dos formas clásicas de visualizar la relación lineal entre 2 variables cuantitativas:\n\n1. Gráficos de dispersión (*Scatterplot*)\n2. Correlograma\n\nPara realizar un scatterplot en `R`, utilicemos el dataset de `USArrests` que contiene datos delictuales de arrestos por cada 100.000 habitantes en los 50 estados de USA en 1973. \n\n```{r, echo=TRUE}\ndata(\"USArrests\")\ncor(USArrests$Murder,USArrests$Assault)\nqplot(Murder,Assault,data = USArrests)\n```\n\nSi quisiéramos ajustar una recta para visualizar si la relación es negativa o positiva y su magnitud (todo esto, según la pendiente de la recta), podemos agregar un `geom_smooth` y especificar que nos ajuste una recta a través del método de regresión lineal (`method = \"lm\"`)\n\n```{r, echo=TRUE}\ncor(USArrests$Murder,USArrests$Rape)\nqplot(Murder, Rape, data = USArrests, geom = c(\"point\", \"smooth\"), method = \"lm\")\n```\n\nSi buscamos visualizar las asociaciones entre distintas variables cuantiativas en un solo gráfico, podemos usar un correlograma mediante la función corrplot\n\n```{r, echo=TRUE}\nlibrary(corrplot)\n\nm <- cor(USArrests)\n\ncorrplot(m, \n         method ='number',\n         type=\"lower\", \n         tl.col=\"black\",pch.col = \"black\"\n         )\n```\n\n## Reflexiones finales [@bruce2020]\n\n::: callout-tip\n### Resumen\n\n-   El análisis de datos exploratorios (EDA), iniciado por John Tukey, sentó las bases para el campo de la ciencia de datos. La idea clave  de EDA es que el primer y más importante paso en cualquier proyecto basado en datos es observar los mismos. Al resumir y visualizar los datos, se puede obtener una valiosa intuición y comprensión del objetivo que se busca resolver.\n-   El conjunto diverso de herramientas y técnicas que está desarrollando la comunidad de código abierto, combinado con la versatilidad de `R` (y otros softwares de este estilo), ha creado una gran cantidad de formas de explorar y analizar datos.\n-   El análisis exploratorio debiese ser la piedra angular de cualquier proyecto de ciencia de datos.\n:::\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","filters":["webr"],"toc-depth":4,"css":["include/webex.css"],"include-after-body":["include/webex.js"],"output-file":"c0_descriptivo.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.39","editor":"visual","webr":{"show-startup-message":true},"theme":["cosmo","r4ds.scss"],"number-depth":4,"code-summary":"Quiero ver mi código","author-meta":"Gabriel Duarte Zuñiga","callout-appearance":"simple","bibliography":["references.bib"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}